import os
import aiohttp
import asyncio
import time
from collections import defaultdict
import re

# é…ç½®
CONFIG = {
    "timeout": 10,  # Timeout in seconds
    "max_parallel": 30,  # Max concurrent requests
    "output_file": "best_sorted.m3u",  # Output file for the sorted M3U
    "iptv_directory": "IPTV"  # Directory containing IPTV files
}


# è¯»å– CCTV é¢‘é“åˆ—è¡¨
def load_cctv_channels(file_path=".github/workflows/IPTV/CCTV.txt"):
    """ä»æ–‡ä»¶åŠ è½½ CCTV é¢‘é“åˆ—è¡¨"""
    cctv_channels = set()
    try:
        with open(file_path, 'r', encoding='utf-8') as file:
            for line in file:
                line = line.strip()
                if line:  # Ignore empty lines
                    cctv_channels.add(line)
    except FileNotFoundError:
        print(f"Error: The file {file_path} was not found.")
    return cctv_channels


# è¯»å– IPTV ç›®å½•ä¸‹æ‰€æœ‰çœä»½é¢‘é“æ–‡ä»¶
def load_province_channels(directory="IPTV"):
    """åŠ è½½æ‰€æœ‰çœä»½çš„é¢‘é“åˆ—è¡¨"""
    province_channels = defaultdict(set)

    for filename in os.listdir(directory):
        if filename.endswith(".txt") and filename != "CCTV.txt":  # æ’é™¤ CCTV.txt æ–‡ä»¶
            province_name = filename.replace(".txt", "")  # ä½¿ç”¨æ–‡ä»¶åä½œä¸ºçœä»½åç§°
            file_path = os.path.join(directory, filename)

            try:
                with open(file_path, 'r', encoding='utf-8') as file:
                    for line in file:
                        line = line.strip()
                        if line:  # Ignore empty lines
                            province_channels[province_name].add(line)
            except FileNotFoundError:
                print(f"Error: The file {file_path} was not found.")

    return province_channels


# æ­£è§„åŒ– CCTV é¢‘é“åç§°
def normalize_cctv_name(channel_name):
    """å°† CCTV é¢‘é“åç§°è¿›è¡Œæ­£è§„åŒ–ï¼Œä¾‹å¦‚ CCTV-1 -> CCTV1"""
    return re.sub(r'CCTV[-]?(\d+)', r'CCTV\1', channel_name)


# ä» TXT æ–‡ä»¶ä¸­æå– IPTV é“¾æ¥
def extract_urls_from_txt(content):
    """ä» TXT æ–‡ä»¶ä¸­æå– IPTV é“¾æ¥"""
    urls = []
    for line in content.splitlines():
        line = line.strip()
        if line and ',' in line:  # æ ¼å¼åº”è¯¥æ˜¯: <é¢‘é“å>,<URL>
            parts = line.split(',', 1)
            urls.append(parts)  # æå–é¢‘é“åå’Œ URL
    return urls


# ä» M3U æ–‡ä»¶ä¸­æå– IPTV é“¾æ¥
def extract_urls_from_m3u(content):
    """ä» M3U æ–‡ä»¶ä¸­æå– IPTV é“¾æ¥"""
    urls = []
    lines = content.splitlines()
    channel = "Unknown"

    for line in lines:
        line = line.strip()
        if line.startswith("#EXTINF:"):
            # ä» EXTINF æ ‡ç­¾ä¸­æå–é¢‘é“å
            parts = line.split(',', 1)
            channel = parts[1] if len(parts) > 1 else "Unknown"
        elif line.startswith(('http://', 'https://')):
            urls.append((channel, line))  # å­˜å‚¨é¢‘é“å’Œ URL çš„å…ƒç»„
    return urls


# æµ‹è¯• IPTV é“¾æ¥çš„å¯ç”¨æ€§å’Œé€Ÿåº¦
async def test_stream(url):
    """æµ‹è¯• IPTV é“¾æ¥çš„å¯ç”¨æ€§å’Œé€Ÿåº¦"""
    async with aiohttp.ClientSession(cookie_jar=None) as session:  # ç¦ç”¨ cookie å¤„ç†
        start_time = time.time()
        try:
            async with session.get(url, timeout=CONFIG["timeout"]) as response:
                if response.status == 200:
                    # è®¡ç®—å“åº”æ—¶é—´
                    elapsed_time = time.time() - start_time
                    return True, elapsed_time
                else:
                    return False, None
        except asyncio.TimeoutError:
            return False, None
        except Exception as e:
            return False, None


# æµ‹è¯•å¤šä¸ª IPTV é“¾æ¥
async def test_multiple_streams(urls):
    """æµ‹è¯•å¤šä¸ª IPTV é“¾æ¥"""
    tasks = [test_stream(url) for _, url in urls]
    results = await asyncio.gather(*tasks)
    return results


# è¯»å–æ–‡ä»¶å¹¶æå– URLï¼ˆæ”¯æŒ M3U æˆ– TXT æ ¼å¼ï¼‰
async def read_and_test_file(file_path, is_m3u=False):
    """è¯»å–æ–‡ä»¶å¹¶æå– URL è¿›è¡Œæµ‹è¯•"""
    try:
        # è·å–æ–‡ä»¶å†…å®¹
        async with aiohttp.ClientSession(cookie_jar=None) as session:  # ç¦ç”¨ cookie å¤„ç†
            async with session.get(file_path) as response:
                content = await response.text()

        # æå– URL
        if is_m3u:
            entries = extract_urls_from_m3u(content)
        else:
            entries = extract_urls_from_txt(content)

        # æµ‹è¯• URL çš„å¯ç”¨æ€§
        valid_urls = []
        results = await test_multiple_streams(entries)
        for (is_valid, _), (channel, url) in zip(results, entries):
            if is_valid:
                valid_urls.append((channel, url))

        return valid_urls

    except Exception as e:
        return []


# ç”Ÿæˆæ’åºåçš„ M3U æ–‡ä»¶
def generate_sorted_m3u(valid_urls, cctv_channels, province_channels, filename):
    """ç”Ÿæˆæ’åºåçš„ M3U æ–‡ä»¶"""
    cctv_channels_list = []
    province_channels_list = defaultdict(list)
    satellite_channels = []
    other_channels = []

    for channel, url in valid_urls:
        normalized_channel = normalize_cctv_name(channel)

        if normalized_channel in cctv_channels:
            cctv_channels_list.append({
                "channel": channel,
                "url": url,
                "logo": f"https://live.fanmingming.cn/tv/{channel}.png",
                "group_title": "å¤®è§†é¢‘é“"
            })
        elif "å«è§†" in channel:  # å«è§†é¢‘é“
            satellite_channels.append({
                "channel": channel,
                "url": url,
                "logo": f"https://live.fanmingming.cn/tv/{channel}.png",
                "group_title": "å«è§†é¢‘é“"
            })
        elif any(province in channel for province in province_channels):  # æœ¬åœ°çœä»½é¢‘é“
            for province, channels in province_channels.items():
                if channel in channels:
                    province_channels_list[province].append({
                        "channel": channel,
                        "url": url,
                        "logo": f"https://live.fanmingming.cn/tv/{channel}.png",
                        "group_title": f"{province}"
                    })
        else:
            other_channels.append({
                "channel": channel,
                "url": url,
                "logo": f"https://live.fanmingming.cn/tv/{channel}.png",
                "group_title": "å…¶ä»–é¢‘é“"
            })

    # æ’åºï¼šçœä»½é¢‘é“ã€å«è§†é¢‘é“ã€å…¶ä»–é¢‘é“
    for province in province_channels_list:
        province_channels_list[province].sort(key=lambda x: x["channel"])

    satellite_channels.sort(key=lambda x: x["channel"])
    other_channels.sort(key=lambda x: x["channel"])

    # åˆå¹¶æ‰€æœ‰é¢‘é“ï¼šCCTV -> å«è§†é¢‘é“ -> çœä»½é¢‘é“ -> å…¶ä»–
    all_channels = cctv_channels_list + satellite_channels + \
                   [channel for province in sorted(province_channels_list) for channel in
                    province_channels_list[province]] + \
                   other_channels

    # å†™å…¥ M3U æ–‡ä»¶
    with open(filename, 'w', encoding='utf-8') as f:
        f.write("#EXTM3U\n")
        for channel_info in all_channels:
            f.write(
                f"#EXTINF:-1 tvg-name=\"{channel_info['channel']}\" tvg-logo=\"{channel_info['logo']}\" group-title=\"{channel_info['group_title']}\",{channel_info['channel']}\n")
            f.write(f"{channel_info['url']}\n")


# åŠ è½½çœä»½é¢‘é“åˆ—è¡¨
def load_province_channels(files):
    """åŠ è½½å¤šä¸ªçœä»½çš„é¢‘é“åˆ—è¡¨"""
    province_channels = defaultdict(set)

    for file_path in files:
        province_name = os.path.basename(file_path).replace(".txt", "")  # ä½¿ç”¨æ–‡ä»¶åä½œä¸ºçœä»½åç§°

        try:
            with open(file_path, 'r', encoding='utf-8') as file:
                for line in file:
                    line = line.strip()
                    if line:  # å¿½ç•¥ç©ºè¡Œ
                        province_channels[province_name].add(line)
        except FileNotFoundError:
            print(f"Error: The file {file_path} was not found.")

    return province_channels


# ä¸»å‡½æ•°ï¼šå¤„ç†å¤šä¸ªæ–‡ä»¶å¹¶ç”Ÿæˆ M3U è¾“å‡º
async def main(file_urls, cctv_channel_file, province_channel_files):
    """ä¸»å‡½æ•°å¤„ç†å¤šä¸ªæ–‡ä»¶"""
    # åŠ è½½ CCTV é¢‘é“åˆ—è¡¨
    cctv_channels = load_cctv_channels(cctv_channel_file)

    # åŠ è½½å¤šä¸ªçœä»½é¢‘é“åˆ—è¡¨
    province_channels = load_province_channels(province_channel_files)

    all_valid_urls = []

    for file_url in file_urls:
        if file_url.endswith(('.m3u', '.m3u8')):
            valid_urls = await read_and_test_file(file_url, is_m3u=True)
        elif file_url.endswith('.txt'):
            valid_urls = await read_and_test_file(file_url, is_m3u=False)
        else:
            valid_urls = []

        all_valid_urls.extend(valid_urls)

    # ç”Ÿæˆæ’åºåçš„ M3U æ–‡ä»¶
    generate_sorted_m3u(all_valid_urls, cctv_channels, province_channels, CONFIG["output_file"])
    print(f"ğŸ‰ Generated sorted M3U file: {CONFIG['output_file']}")


if __name__ == "__main__":
    # IPTV æ–‡ä»¶ URLï¼ˆæ‚¨å¯ä»¥æ·»åŠ è‡ªå·±çš„æ–‡ä»¶ URL åˆ—è¡¨ï¼‰
    file_urls = [
        "https://tzdr.com/iptv.txt",
        "https://live.kilvn.com/iptv.m3u",
        "https://cdn.jsdelivr.net/gh/Guovin/iptv-api@gd/output/result.m3u",
        "https://gh-proxy.com/raw.githubusercontent.com/vbskycn/iptv/refs/heads/master/tv/iptv4.m3u",
        "http://175.178.251.183:6689/live.m3u",
        "https://m3u.ibert.me/ycl_iptv.m3u"
    ]

    # CCTV é¢‘é“æ–‡ä»¶ï¼ˆä¾‹å¦‚ IPTV/CCTV.txtï¼‰
    cctv_channel_file = ".github/workflows/IPTV/CCTV.txt"

    # çœä»½é¢‘é“æ–‡ä»¶åˆ—è¡¨
    province_channel_files = [
        ".github/workflows/IPTV/é‡åº†é¢‘é“.txt",
        ".github/workflows/IPTV/å››å·é¢‘é“.txt",
        ".github/workflows/IPTV/äº‘å—é¢‘é“.txt",
        ".github/workflows/IPTV/å®‰å¾½é¢‘é“.txt",
        ".github/workflows/IPTV/ç¦å»ºé¢‘é“.txt",
        ".github/workflows/IPTV/ç”˜è‚ƒé¢‘é“.txt",
        ".github/workflows/IPTV/å¹¿ä¸œé¢‘é“.txt",
        ".github/workflows/IPTV/å¹¿è¥¿é¢‘é“.txt",
        ".github/workflows/IPTV/è´µå·é¢‘é“.txt",
        ".github/workflows/IPTV/æµ·å—é¢‘é“.txt",
        ".github/workflows/IPTV/æ²³åŒ—é¢‘é“.txt",
        ".github/workflows/IPTV/æ²³å—é¢‘é“.txt",
        ".github/workflows/IPTV/é»‘é¾™æ±Ÿé¢‘é“.txt",
        ".github/workflows/IPTV/æ¹–åŒ—é¢‘é“.txt",
        ".github/workflows/IPTV/æ¹–å—é¢‘é“.txt",
        ".github/workflows/IPTV/å‰æ—é¢‘é“.txt",
        ".github/workflows/IPTV/æ±Ÿè‹é¢‘é“.txt",
        ".github/workflows/IPTV/æ±Ÿè¥¿é¢‘é“.txt",
        ".github/workflows/IPTV/è¾½å®é¢‘é“.txt",
        ".github/workflows/IPTV/å†…è’™é¢‘é“.txt",
        ".github/workflows/IPTV/å®å¤é¢‘é“.txt",
        ".github/workflows/IPTV/é’æµ·é¢‘é“.txt",
        ".github/workflows/IPTV/å±±ä¸œé¢‘é“.txt",
        ".github/workflows/IPTV/å±±è¥¿é¢‘é“.txt",
        ".github/workflows/IPTV/é™•è¥¿é¢‘é“.txt",
        ".github/workflows/IPTV/ä¸Šæµ·é¢‘é“.txt",
        ".github/workflows/IPTV/å¤©æ´¥é¢‘é“.txt",
        ".github/workflows/IPTV/å«è§†é¢‘é“.txt",
        ".github/workflows/IPTV/æ–°ç–†é¢‘é“.txt",
        ".github/workflows/IPTV/äº‘å—é¢‘é“.txt",
        ".github/workflows/IPTV/æµ™æ±Ÿé¢‘é“.txt",
        ".github/workflows/IPTV/åŒ—äº¬é¢‘é“.txt"
    ]

    # æ‰§è¡Œä¸»å‡½æ•°
    asyncio.run(main(file_urls, cctv_channel_file, province_channel_files))
